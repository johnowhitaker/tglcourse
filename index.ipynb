{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from genai.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Generative Landscape\n",
    "\n",
    "> A WIP course designed to get you up to speed on the exciting field of generative modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all still TODO - I'm aining to finish towards the end of 2022 so please ignore this until then ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum plan\n",
    "\n",
    "### Topics:\n",
    "- Intro: The Generative Landscape\n",
    "- PyTorch, AutoGrad and Gradient Descent\n",
    "- Constructing ANNs, Loss Functions\n",
    "- Representations: What do ANNs Learn? Style Transfer\n",
    "- CLIP/CLOOB: Multiple Modalities in a Shared Latent Space. Use as a loss function\n",
    "- Generative modelling: Noise -> Data (Auto-Encoders and VAEs)\n",
    "- GANs 1 - GAN training, a simple DC-GAN\n",
    "- GANs 2 - Conditioning, Improvements, Modern GANs, CLIP guidance\n",
    "- Sequence Modelling 1 - Ideas, RNNs, Language Models as Representation Learners\n",
    "- Sequence Modelling 2 - Transformers\n",
    "- Sequence Modelling 3 - Everything is a sequence (VIT, VQGANs, Dalle-mini, Parti, flamingo, music generation, other applications)\n",
    "- Diffusion Models 1 - A New Type of Generative Model\n",
    "- Diffusion Models 2 - Conditioning, Guiding, Improvements\n",
    "- Diffusion Models 3 - The Current DM Landscape, Using Diffusion Models Creatively (inpainting, guiding, animation)\n",
    "- Spotlight: Audio\n",
    "- Spotlight: Video\n",
    "\n",
    "### Extra Skills:\n",
    "- **Ethics in generative modelling**\n",
    "- Fine-tuning existing models\n",
    "- Working with GPUs\n",
    "- Multi-GPU or TPU training\n",
    "- Experiment Tracking (eg W&B)\n",
    "- Sharing demos w/ Gradio\n",
    "- Managing cloud machines\n",
    "- Datasets and Dataloaders Intro (also defines data util funcs for the rest of the course)\n",
    "- Dataloaders deep dive, streaming data\n",
    "- Navigating other codebases\n",
    "- Version control and CI (+ NBDev)\n",
    "\n",
    "### Projects:\n",
    "- Train a GAN, explore hyperparameters\n",
    "- Fine-tune a diffusion model on a custom dataset\n",
    "- Create and share a final project, including a report and demo\n",
    "\n",
    "### Guest Discussions\n",
    "- 'Prompt engineering' with Joshua Herman\n",
    "- Keeping up with multimodal art with Apolinario\n",
    "- Going deep with VQGAN+CLIP - Remi\n",
    "- Softology \n",
    "- Rivers\n",
    "- Artist interview: M Klingelmann\n",
    "- Stability AI w/ Emad\n",
    "- AI art and community with Kali (fine-tuning diffusion queen)\n",
    "- Maybe Disco?\n",
    "- Maybe Midjourney (talk to D russ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the overall structure?\n",
    "\n",
    "\n",
    "Stuff that should go in somewhere:\n",
    "- \"Text inversion\" (https://arxiv.org/pdf/2208.01618.pdf)\n",
    "- Lots of paper readings / sumaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generative Landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code example?\n"
     ]
    }
   ],
   "source": [
    "print('Code example?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
