{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065bfd42-a9cc-490e-a0d9-1cd676a36e27",
   "metadata": {},
   "source": [
    "# Lesson 4: Learning Representations + Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee9837-2143-4367-90de-0221e6a599b7",
   "metadata": {},
   "source": [
    "Video: What do networks learn?\n",
    "\n",
    "Look at https://distill.pub/2017/feature-visualization/ and show some of that\n",
    "\n",
    "Look at https://distill.pub/2021/multimodal-neurons/ for some fancier concepts in CLIP\n",
    "\n",
    "Talk about fine-tuning a little and link to bonus content on that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa5b03-a705-48c5-a2ca-8083baaf117c",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70877a-a943-42cc-9122-00c22fddc2d4",
   "metadata": {},
   "source": [
    "## Style Transfer\n",
    "\n",
    "Remember how we said that early layers in a network tend to learn simpler features like colour and texture, while later layers capture more complex shapes? We're going to take advantage of this to do a little bit of magic. We'll take two images, a content image and a style image. Then we'll feed both through a network and record the activations at various layers.\n",
    "\n",
    "Now we can start with noise or begin with the content image, and set it up as a tensor to be optimised. Then, we start tweaking it such that when we feed it through the same big network the activations in the early layers ('style') are similar to those of the style image while the activations of later layers, more linked to overall structure and shapes ('content') match the content image. \n",
    "\n",
    "In effect we're trying to minimise some combination of two loss functions, a style loss and a content loss. \n",
    "\n",
    "First, let's look at a pretrained network and pull some features from it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c387b-705b-4cf1-be37-338e46ba3e79",
   "metadata": {},
   "source": [
    "### Extracting Represenations from Pretrained Models\n",
    "\n",
    "VGG16 was a fairly popular CNN that improved upon the famous AlexNet architecture. It has since been supeceeded by more complex networks but it still works great for our purposes. The architecture is something like the following ([source](https://https://neurohive.io/en/popular-networks/vgg16/)):\n",
    "\n",
    "![architecture](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)\n",
    "\n",
    "We can load it like so (check the imports section at the start of this notebook for the relevant imports):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f20ec4-b3d1-494d-8aa6-3c73c6d10c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f2795-4982-4ce7-9ff1-e4a60ecbab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg # Uncomment to show the sumary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9deb1a-57f1-4d85-acc4-e792e906ce57",
   "metadata": {},
   "source": [
    "Page stats: Total Hits: [![HitCount](https://hits.dwyl.com/johnowhitaker/tglcourse.svg?style=flat-square&show=unique)](http://hits.dwyl.com/johnowhitaker/tglcourse)\n",
    "Page visitors:\n",
    "![visitor badge](https://page-views.glitch.me/badge?page_id=tglcourse.l04)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
