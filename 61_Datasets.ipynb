{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfe632-724e-4a54-b3c7-998f4430e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp data_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae16856-7b8d-4986-b97f-bf28216f6c43",
   "metadata": {},
   "source": [
    "# Datasets and General Data Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80afd6-fb10-4799-8ddc-c7faf29c17d3",
   "metadata": {},
   "source": [
    "For many tasks in machine learning, the actual model training is the easy bit! Many data scientists spend most of their time sourcing and exploring data, and getting it into the right format ready for modelling. Lucky for us, most of the data we'll use for demos during this course has already been collected and organised for us, and to make things even more convenient during the lessons themselves we're going to lay some additional groundwork here in this notebook. \n",
    "\n",
    "Motivate dataloaders\n",
    "Batching\n",
    "Advantage of pre-fetching the next batch\n",
    "Mention monitoring GPU usage and watching for CPU bottlenecks in the dataloaders\n",
    "Dive into pytorch dataloaders\n",
    "HF Hub and datasets library\n",
    "\n",
    "DATA UTILS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d548aa2-795f-4df7-87a6-879defdd5343",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_279149/3650052427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#|export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtglcourse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "import torch\n",
    "import datasets\n",
    "from tglcourse.utils import *\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfc254-2f8d-4a0c-bf66-6f78590e2345",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb3220-88ca-4b78-9df0-b9561e4968ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
