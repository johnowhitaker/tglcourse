{
 "cells": [
  {
   "cell_type": "raw",
   "id": "25e23ada-5b6b-401e-b9bc-3c109e2df99d",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  eval: false\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfe632-724e-4a54-b3c7-998f4430e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp data_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae16856-7b8d-4986-b97f-bf28216f6c43",
   "metadata": {},
   "source": [
    "# Datasets and General Data Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80afd6-fb10-4799-8ddc-c7faf29c17d3",
   "metadata": {},
   "source": [
    "For many tasks in machine learning, the actual model training is the easy bit! Many data scientists spend most of their time sourcing and exploring data, and getting it into the right format ready for modelling. Lucky for us, most of the data we'll use for demos during this course has already been collected and organised for us, and to make things even more convenient during the lessons themselves we're going to lay some additional groundwork here in this notebook. \n",
    "\n",
    "Motivate dataloaders\n",
    "Batching\n",
    "Advantage of pre-fetching the next batch\n",
    "Mention monitoring GPU usage and watching for CPU bottlenecks in the dataloaders\n",
    "Dive into pytorch dataloaders\n",
    "HF Hub and datasets library\n",
    "\n",
    "https://huggingface.co/docs/datasets/quickstart\n",
    "\n",
    "\n",
    "https://huggingface.co/docs/datasets/stream\n",
    "\n",
    "DATA UTILS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d548aa2-795f-4df7-87a6-879defdd5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "import datasets\n",
    "from tglcourse.utils import *\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfc254-2f8d-4a0c-bf66-6f78590e2345",
   "metadata": {},
   "source": [
    "### TODO redo this and integrate into notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9be741-4c4e-41c4-b78f-46dbd1461253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def mnist_transform(example):\n",
    "    example[\"image\"] = [T.ToTensor()(image) for image in example[\"image\"]]\n",
    "    return example\n",
    "\n",
    "# Re-create the streaming example above\n",
    "def get_mnist_dl(batch_size=32, split='train'):\n",
    "    mnist_dataset = load_dataset('mnist', split=split)\n",
    "    mnist_dataset = mnist_dataset.with_transform(mnist_transform)\n",
    "    dataloader = DataLoader(mnist_dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b10f5-6ff9-4276-a8cc-2521d3a73b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "tfm = T.Compose([T.ToTensor(), T.Resize(320), T.CenterCrop(320)])\n",
    "def imagewoof_transform(example):\n",
    "    example[\"image\"] = [tfm(image.convert('RGB')) for image in example[\"image\"]]\n",
    "    return example\n",
    "def get_imagewoof_dl(batch_size=32):\n",
    "    dataset = load_dataset('johnowhitaker/imagewoof2-320', split='train').shuffle(seed=42)\n",
    "    dataset = dataset.with_transform(imagewoof_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eeba4c-41a4-4389-8944-7f904c9173d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "tfm = T.Compose([T.ToTensor(), T.Resize(32), T.CenterCrop(32)])\n",
    "def cifar10_transform(example):\n",
    "    example[\"image\"] = [tfm(image.convert('RGB')) for image in example[\"image\"]]\n",
    "    return example\n",
    "def get_cifar10_dl(batch_size=32, split='train'):\n",
    "    dataset = load_dataset('cifar10', split=split).shuffle(seed=42).rename_column(\"img\", \"image\")\n",
    "    dataset = dataset.with_transform(cifar10_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d660c68-337f-43e1-b876-e4f9e3f0702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cifar10 (/root/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4)\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4/cache-16b9e105e7ead8c5.arrow\n",
      "Parameter 'transform'=<function cifar10_transform> of the transform datasets.arrow_dataset.Dataset.set_format couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 32, 32]),\n",
       " tensor([1, 2, 6, 7, 9, 4, 7, 6, 4, 2, 2, 0, 4, 8, 4, 2, 5, 7, 2, 9, 9, 8, 8, 1,\n",
       "         4, 3, 7, 3, 5, 6, 9, 3, 6, 4, 3, 4, 7, 9, 3, 3, 0, 6, 4, 3, 5, 1, 9, 6,\n",
       "         2, 2, 1, 0, 6, 7, 4, 3, 1, 4, 4, 2, 2, 5, 4, 5, 7, 0, 3, 0, 8, 4, 5, 7,\n",
       "         9, 0, 9, 9, 9, 4, 8, 3, 3, 6, 5, 5, 3, 2, 8, 1, 4, 3, 4, 2, 7, 8, 2, 0,\n",
       "         9, 6, 8, 7, 4, 3, 2, 0, 2, 0, 3, 2, 4, 9, 2, 5, 9, 6, 0, 6, 0, 7, 2, 2,\n",
       "         1, 7, 5, 9, 6, 8, 6, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = get_cifar10_dl(batch_size=128, split='train')\n",
    "batch = next(iter(dataloader))\n",
    "batch['image'].shape, batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bdaf4-f661-4946-85f1-5c36c4de206f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
