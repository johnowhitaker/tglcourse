{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfe632-724e-4a54-b3c7-998f4430e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp data_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae16856-7b8d-4986-b97f-bf28216f6c43",
   "metadata": {},
   "source": [
    "# Datasets and General Data Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80afd6-fb10-4799-8ddc-c7faf29c17d3",
   "metadata": {},
   "source": [
    "For many tasks in machine learning, the actual model training is the easy bit! Many data scientists spend most of their time sourcing and exploring data, and getting it into the right format ready for modelling. Lucky for us, most of the data we'll use for demos during this course has already been collected and organised for us, and to make things even more convenient during the lessons themselves we're going to lay some additional groundwork here in this notebook. \n",
    "\n",
    "Motivate dataloaders\n",
    "Batching\n",
    "Advantage of pre-fetching the next batch\n",
    "Mention monitoring GPU usage and watching for CPU bottlenecks in the dataloaders\n",
    "Dive into pytorch dataloaders\n",
    "HF Hub and datasets library\n",
    "\n",
    "https://huggingface.co/docs/datasets/quickstart\n",
    "\n",
    "\n",
    "https://huggingface.co/docs/datasets/stream\n",
    "\n",
    "DATA UTILS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d548aa2-795f-4df7-87a6-879defdd5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "import datasets\n",
    "from tglcourse.utils import *\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfc254-2f8d-4a0c-bf66-6f78590e2345",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb3220-88ca-4b78-9df0-b9561e4968ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mnist (/home/jonathan/.cache/huggingface/datasets/mnist/mnist/1.0.0/fda16c03c4ecfb13f165ba7e29cf38129ce035011519968cdaf74894ce91c9d4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a79f09c8a984b778609709948386086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 60000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "mnist_dataset = load_dataset('mnist') # It's on HF\n",
    "mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565857e2-da6f-4e1f-9571-cb64455efbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "# View the label and image for the first example:\n",
    "print(mnist_dataset['train'][0]['label'])\n",
    "mnist_dataset['train'][0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea6af65-1be5-4dad-9b65-5ee50c42c05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 28, 28]), tensor([5, 0, 4, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "# Create a dataloader, with some pre-processing:\n",
    "\n",
    "# A function to get our data in the right format: in this case just converting the image to a tensor\n",
    "def transform(example):\n",
    "    example[\"image\"] = [T.ToTensor()(image) for image in example[\"image\"]]\n",
    "    return example\n",
    "\n",
    "# Add this as a transform to the dataset\n",
    "mnist_dataset = mnist_dataset.with_transform(transform)\n",
    "\n",
    "# Create a pytorch dataloader with this, specifically just the 'train' set\n",
    "dataloader = DataLoader(mnist_dataset['train'], batch_size=4)\n",
    "\n",
    "# Get one batch of data:\n",
    "images, labels = next(iter(dataloader)).values() # It returns a dict by default, .values gets just the data\n",
    "images.shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a516708-2bdd-4384-b29e-6a94c6024b3b",
   "metadata": {},
   "source": [
    "Another way to do this would be to define our own dataset class which needs to implement `__init__`, `__len__` and `__getitem__`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a65b2-16ee-4e3a-95de-03f272f2bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mnist (/home/jonathan/.cache/huggingface/datasets/mnist/mnist/1.0.0/fda16c03c4ecfb13f165ba7e29cf38129ce035011519968cdaf74894ce91c9d4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 28, 28]), tensor([5, 0, 4, 1, 9, 2, 1, 3]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "class MNIST_DATASET(Dataset):\n",
    "    \"\"\"One option: custom Dataset class\"\"\"\n",
    "    def __init__(self, split='train'):\n",
    "        self.dataset = load_dataset('mnist', split=split)\n",
    "        self.preprocess = T.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.dataset[idx]\n",
    "        return (self.preprocess(x['image']), x['label'])\n",
    "        \n",
    "dataset = MNIST_DATASET(split='train')\n",
    "dataloader = DataLoader(dataset, batch_size=8)\n",
    "images, labels = next(iter(dataloader))\n",
    "images.shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78696138-1d90-42a6-8f39-e68ef7adba97",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a2066-5801-4ad2-83a9-dbb2caf15f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28]) tensor([5, 0, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "# Load the dataset from HF with streaming=True this time\n",
    "mnist_dataset = load_dataset('mnist', split='train', streaming=True) \n",
    "\n",
    "# Apply the pre-processing\n",
    "mnist_dataset = mnist_dataset.map(transform, batched=True)\n",
    "\n",
    "# Format for pytorch\n",
    "mnist_dataset = mnist_dataset.with_format(\"torch\")\n",
    "\n",
    "# Shuffle the dataset (optional, buffer size is how much is loaded to shuffle\n",
    "# mnist_dataset = mnist_dataset.shuffle(seed=42, buffer_size=500)\n",
    "\n",
    "# Create the dataloader, with the transforms passed as the collate_fn\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=4)\n",
    "\n",
    "# Now we can get a batch as usual, but it doesn't need to download anything in advance!\n",
    "images, labels = next(iter(dataloader)).values()\n",
    "print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee09537-9fbe-4ab6-b9f5-24c3aeb3ea4d",
   "metadata": {},
   "source": [
    "## Specifying some datasets for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae6590-f328-4be2-9111-ac9c117a9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# Specify the pre-processing\n",
    "to_tensor = T.ToTensor()\n",
    "def mnist_transform(example):\n",
    "    example[\"image\"] = [to_tensor(image) for image in example[\"image\"]]\n",
    "    return example\n",
    "\n",
    "# Re-create the streaming example above\n",
    "def get_mnist_dl(batch_size=32, streaming=True):\n",
    "    mnist_dataset = load_dataset('mnist', split='train', streaming=streaming)\n",
    "    if streaming:\n",
    "        mnist_dataset = mnist_dataset.map(mnist_transform, batched=True)\n",
    "        mnist_dataset = mnist_dataset.with_format(\"torch\")\n",
    "    else:\n",
    "        mnist_dataset = mnist_dataset.with_transform(transform)\n",
    "    dataloader = DataLoader(mnist_dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806eed03-9d9f-4763-880c-d3ccc0974a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# Test this\n",
    "dl = get_mnist_dl()\n",
    "images, labels = next(iter(dl)).values()\n",
    "print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67403098-3872-42a7-8c37-1fa2fe062fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 77.1 ms, total: 17.5 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "%%time\n",
    "for images, labels in dl:\n",
    "    a = images*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd007b-2dde-47fb-b481-1be4b5083512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mnist (/home/jonathan/.cache/huggingface/datasets/mnist/mnist/1.0.0/fda16c03c4ecfb13f165ba7e29cf38129ce035011519968cdaf74894ce91c9d4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# We can pass streaming=False here to force the download of the whole dataset:\n",
    "dl = get_mnist_dl(streaming=False)\n",
    "images, labels = next(iter(dl)).values()\n",
    "print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf437682-fbd9-40c1-ba1a-563404a8e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 0 ns, total: 13.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "%%time\n",
    "for images, labels in dl:\n",
    "    a = images*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98250ad4-a426-4ddc-9853-ac767408c878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f4f62-26e1-493c-9794-834420be8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO celebA and imagewoof from https://github.com/johnowhitaker/cclddg/blob/master/02_Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9be741-4c4e-41c4-b78f-46dbd1461253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
