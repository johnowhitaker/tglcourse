{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32abc01-b8f8-430f-944f-45304dcdd111",
   "metadata": {},
   "source": [
    "# Lesson 9: Introduction to Sequence Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efb243-db58-4b98-aea8-648a091cc79b",
   "metadata": {},
   "source": [
    "Intro - lots of things come as sequences, and text is common!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ded1f-8b94-4865-901f-8ced5b332e1e",
   "metadata": {},
   "source": [
    "## Embeddings: Working With Tokens\n",
    "\n",
    "Concept of embeddings\n",
    "\n",
    "Reference https://deeplearning.neuromatch.io/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial1.html and maybe link Lyle's 'Embeddings Rule' video?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c15b27-4d9b-4477-a1c6-d9b4635e2df5",
   "metadata": {},
   "source": [
    "## Modelling Sequences: Language Models\n",
    "\n",
    "Explain the objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b432e-b24a-4514-acff-f1174ebf9e6a",
   "metadata": {},
   "source": [
    "## A simple MLP\n",
    "\n",
    "Similar to Karpathy's makemore demo (TODO link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc6b27-714c-4602-a583-c6cb28b60791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "754d3f2c-4773-4e25-b1db-12498b7cbc34",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks and LSTMs\n",
    "\n",
    "Explain the basic architecture\n",
    "\n",
    "Maybe demo?\n",
    "\n",
    "Brief hand-wave explanation of LSTMs and link ULMFIT and co for the curious\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48444bb-cb69-4dda-9304-593669f7b3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 8, 20]), torch.Size([1, 8, 20]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Create the RNN\n",
    "input_size = 10 # Number of features in the input (embedding dim)\n",
    "hidden_size = 20 # Number of features in the hidden state h\n",
    "num_layers = 1 # Set to 2 for a 'stacked' RNN with 2 layers\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers) # The model\n",
    "\n",
    "# Run some dummy data through\n",
    "# Create the model with batch_first=True if you'd like the batch dimension to come first\n",
    "batch_size = 8\n",
    "input_length = 5\n",
    "x = torch.randn(5, batch_size, input_size)\n",
    "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "output, hn = rnn(x, h0)\n",
    "\n",
    "# Check the output shapes\n",
    "output.shape, hn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6643e-7962-4706-bd65-a80f6fb6d1e3",
   "metadata": {},
   "source": [
    "## Using Learned Representations\n",
    "\n",
    "Do review classification or something using a learned embedding combined with an RNN? Or model tunes and then classify into type/key/mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948ef50-3e0e-4bb1-999c-65652ef91d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2fbaa58-e6d4-4ea2-9d37-d9df4143542f",
   "metadata": {},
   "source": [
    "Page stats: Total Hits: [![HitCount](https://hits.dwyl.com/johnowhitaker/tglcourse.svg?style=flat-square&show=unique)](http://hits.dwyl.com/johnowhitaker/tglcourse)\n",
    "Page visitors:\n",
    "![visitor badge](https://page-views.glitch.me/badge?page_id=tglcourse.l09)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
