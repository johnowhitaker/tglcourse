{
 "cells": [
  {
   "cell_type": "raw",
   "id": "18b204ac-058f-4041-9349-33e9152655bf",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  eval: false\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32abc01-b8f8-430f-944f-45304dcdd111",
   "metadata": {},
   "source": [
    "# Lesson 9: Introduction to Sequence Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efb243-db58-4b98-aea8-648a091cc79b",
   "metadata": {},
   "source": [
    "Intro - lots of things come as sequences, and text is common!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ded1f-8b94-4865-901f-8ced5b332e1e",
   "metadata": {},
   "source": [
    "## Embeddings: Working With Tokens\n",
    "\n",
    "Concept of embeddings\n",
    "\n",
    "Reference https://deeplearning.neuromatch.io/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial1.html and maybe link Lyle's 'Embeddings Rule' video?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8aa97-3b6f-4d81-bb98-360994facb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c15b27-4d9b-4477-a1c6-d9b4635e2df5",
   "metadata": {},
   "source": [
    "## Modelling Sequences: Language Models\n",
    "\n",
    "Explain the objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedefc9c-408d-4d5f-87ba-c6627c1eab5a",
   "metadata": {},
   "source": [
    "## Tokenizing Text\n",
    "\n",
    "How do we split up text into tokens? We often talk about 'words' being the unit of text, but if we just go with a token for each word that we might encounter you'll end up with a massive (1M) vocabulary filled with mostly obscure/misspelled words. But on the other hand letters would mean using far more tokens to represent the same sentence. \n",
    "\n",
    "One solution.. explain wordpiece and co\n",
    "\n",
    "Tokenizers: https://huggingface.co/docs/tokenizers/index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e3eef-7297-42fa-8663-2474b6f745c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a78ad-2bef-4d45-9459-8182de8160ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding: Encoding(num_tokens=9, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "ids: [101, 2054, 1037, 3835, 13109, 9541, 3468, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode('What a nice flooble!')\n",
    "print('Encoding:', encoding)\n",
    "\n",
    "ids = encoding.ids\n",
    "print('ids:', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4e19c-0a8e-438d-960f-b5565d4593d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101:\n",
      "2054:what\n",
      "1037:a\n",
      "3835:nice\n",
      "13109:fl\n",
      "9541:##oo\n",
      "3468:##ble\n",
      "999:!\n",
      "102:\n"
     ]
    }
   ],
   "source": [
    "for t in ids:\n",
    "    print(f'{t}:{tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5a4ad-6e41-49ee-859a-e10ab4806c48",
   "metadata": {},
   "source": [
    "We have special tokens for start (101), end (102), symbols like '!' (999) and separate tokens for a string like 'oo' or 'ble' if they don't occur at the start of a word. Common words get a token, uncommon ones like flooble are broken down into components. THe full vocabulary size of this tokenizer is about 30,000 tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c058da-95dc-4dc0-8c4c-05822a0d37d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.get_vocab().items())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e8521-0df7-4f8c-a76d-b26c40982207",
   "metadata": {},
   "source": [
    "## An Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f667a-d852-4d6a-b863-594e61cc0ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 256)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 256\n",
    "emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca3e06-2111-43b7-b5e0-24340cccd365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer(torch.tensor(ids)).shape # Passing our tokens through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b432e-b24a-4514-acff-f1174ebf9e6a",
   "metadata": {},
   "source": [
    "## A simple MLP\n",
    "\n",
    "Similar to Karpathy's makemore demo (TODO link)\n",
    "\n",
    "How do we work with sequences of different lengths? Padding + truncation seem non-ideal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc6b27-714c-4602-a583-c6cb28b60791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "seq_len=64\n",
    "batch_ids = torch.randint(vocab_size, (batch_size,seq_len))\n",
    "batch_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8fe08-b14e-4a83-9ae0-d13931bce3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer(batch_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c4035-4233-400f-b93c-5100189b402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A minimal model (output sizes shown\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_size, emb_dim), # (batch_size, seq_length, emb_dim)\n",
    "    nn.Flatten(), # (batch_size, seq_length*emb_dim)\n",
    "    nn.Linear(emb_dim*seq_len, 64), # (batch_size, 64)\n",
    "    nn.ReLU(), # (batch_size, 64)\n",
    "    nn.Linear(64, 2), # (batch_size, 2)\n",
    "    \n",
    ")\n",
    "model(batch_ids).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00720574-aab9-404a-8538-5b282399b8bb",
   "metadata": {},
   "source": [
    "Q: What happens when word position changes?\n",
    "Q: Would this work on different length sequences?\n",
    "Q: think of more Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d3f2c-4773-4e25-b1db-12498b7cbc34",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks and LSTMs\n",
    "\n",
    "Explain the basic architecture\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "![an unrolled RNN](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
    "\n",
    "Maybe demo?\n",
    "\n",
    "Brief hand-wave explanation of LSTMs and link ULMFIT and co for the curious\n",
    "\n",
    "Great blog by colah https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "Karpathy on RNN effectiveness: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36c3b0-25de-499d-bf0b-06defc913e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 8, 20]), torch.Size([1, 8, 20]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the RNN\n",
    "input_size = 10 # Number of features in the input (embedding dim)\n",
    "hidden_size = 20 # Number of features in the hidden state h\n",
    "num_layers = 1 # Set to 2 for a 'stacked' RNN with 2 layers\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers) # The model\n",
    "\n",
    "# Run some dummy data through\n",
    "# Create the model with batch_first=True if you'd like the batch dimension to come first\n",
    "batch_size = 8\n",
    "input_length = 5\n",
    "x = torch.randn(5, batch_size, input_size)\n",
    "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "output, hn = rnn(x, h0)\n",
    "\n",
    "# Check the output shapes\n",
    "output.shape, hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf33b33-6c86-4384-a86f-81083c7ff7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyRNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size=10, hidden_size=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.emb_layer = nn.Embedding(vocab_size, input_size)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers)\n",
    "        self.mlp = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb_layer(x) # TO embeddings (batch_size, seq_len, input_size)\n",
    "        net_output, h = self.rnn(x) # Through RNN (batch_size, seq_len, hidden_size)\n",
    "        averaged_output = net_output.mean(dim=1) # Take the mean of the outputs ('mean pooling')\n",
    "        result = self.mlp(averaged_output) # THrough the linear layer or MLP to get 2 outputs (assuming binary classification)\n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c1f5e-5116-4793-a158-cb7bbc5a2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyRNNClassifier()\n",
    "net(batch_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f897aa-527f-4d9e-b9a9-5de126544f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306742"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99478a-433a-40ed-b7e1-5d7390f5b4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([30522, 10]),\n",
       " torch.Size([20, 10]),\n",
       " torch.Size([20, 20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([20, 20]),\n",
       " torch.Size([20, 20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([2, 20]),\n",
       " torch.Size([2])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d9c2f-83d8-45d3-9d43-0fe004ffe548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try on some data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073b4c1-67da-416e-a3f1-021b5ecad590",
   "metadata": {},
   "source": [
    "**LSTMs**\n",
    "\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "something something memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7affb6d-47c6-4b1a-9c38-29869e2a9220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=10, hidden_size=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.emb_layer = nn.Embedding(vocab_size, input_size)\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers)\n",
    "        self.mlp = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb_layer(x) # TO embeddings (batch_size, seq_len, input_size)\n",
    "        net_output, h = self.rnn(x) # Through RNN (batch_size, seq_len, hidden_size)\n",
    "        averaged_output = net_output.mean(dim=1) # Take the mean of the outputs ('mean pooling')\n",
    "        result = self.mlp(averaged_output) # THrough the linear layer or MLP to get 2 outputs (assuming binary classification)\n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5042-f359-4a5d-96fe-9239d85cf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyLSTMClassifier()\n",
    "net(batch_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502b18d-7027-4d74-b8d0-f363794a6705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311182"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6643e-7962-4706-bd65-a80f6fb6d1e3",
   "metadata": {},
   "source": [
    "## Using Learned Representations\n",
    "\n",
    "Do review classification or something using a learned embedding combined with an RNN? Or model tunes and then classify into type/key/mode?\n",
    "\n",
    "Yeah tunes will be good. LM objective first, then re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948ef50-3e0e-4bb1-999c-65652ef91d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try on some data (LM first then new classification head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3d757-227e-47d0-8158-4d1dc5c318cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO talk about efficiency of training vs sampling\n",
    "# TODO demo different sampling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbaa58-e6d4-4ea2-9d37-d9df4143542f",
   "metadata": {},
   "source": [
    "Page stats: Total Hits: [![HitCount](https://hits.dwyl.com/johnowhitaker/tglcourse.svg?style=flat-square&show=unique)](http://hits.dwyl.com/johnowhitaker/tglcourse)\n",
    "Page visitors:\n",
    "![visitor badge](https://page-views.glitch.me/badge?page_id=tglcourse.l09)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
