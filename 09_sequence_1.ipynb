{
 "cells": [
  {
   "cell_type": "raw",
   "id": "18b204ac-058f-4041-9349-33e9152655bf",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  eval: false\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32abc01-b8f8-430f-944f-45304dcdd111",
   "metadata": {},
   "source": [
    "# Lesson 9: Introduction to Sequence Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efb243-db58-4b98-aea8-648a091cc79b",
   "metadata": {},
   "source": [
    "Intro - lots of things come as sequences, and text is common!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ded1f-8b94-4865-901f-8ced5b332e1e",
   "metadata": {},
   "source": [
    "## Embeddings: Working With Tokens\n",
    "\n",
    "Concept of embeddings\n",
    "\n",
    "Reference https://deeplearning.neuromatch.io/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial1.html and maybe link Lyle's 'Embeddings Rule' video?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8aa97-3b6f-4d81-bb98-360994facb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c15b27-4d9b-4477-a1c6-d9b4635e2df5",
   "metadata": {},
   "source": [
    "## Modelling Sequences: Language Models\n",
    "\n",
    "Explain the objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedefc9c-408d-4d5f-87ba-c6627c1eab5a",
   "metadata": {},
   "source": [
    "## Tokenizing Text\n",
    "\n",
    "How do we split up text into tokens? We often talk about 'words' being the unit of text, but if we just go with a token for each word that we might encounter you'll end up with a massive (1M) vocabulary filled with mostly obscure/misspelled words. But on the other hand letters would mean using far more tokens to represent the same sentence. \n",
    "\n",
    "One solution.. explain wordpiece and co\n",
    "\n",
    "Tokenizers: https://huggingface.co/docs/tokenizers/index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e3eef-7297-42fa-8663-2474b6f745c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a78ad-2bef-4d45-9459-8182de8160ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding: Encoding(num_tokens=9, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "ids: [101, 2054, 1037, 3835, 13109, 9541, 3468, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode('What a nice flooble!')\n",
    "print('Encoding:', encoding)\n",
    "\n",
    "ids = encoding.ids\n",
    "print('ids:', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4e19c-0a8e-438d-960f-b5565d4593d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101:\n",
      "2054:what\n",
      "1037:a\n",
      "3835:nice\n",
      "13109:fl\n",
      "9541:##oo\n",
      "3468:##ble\n",
      "999:!\n",
      "102:\n"
     ]
    }
   ],
   "source": [
    "for t in ids:\n",
    "    print(f'{t}:{tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5a4ad-6e41-49ee-859a-e10ab4806c48",
   "metadata": {},
   "source": [
    "We have special tokens for start (101), end (102), symbols like '!' (999) and separate tokens for a string like 'oo' or 'ble' if they don't occur at the start of a word. Common words get a token, uncommon ones like flooble are broken down into components. THe full vocabulary size of this tokenizer is about 30,000 tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c058da-95dc-4dc0-8c4c-05822a0d37d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab().items()) # The vocab size of this tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a74ea-a098-432e-b32e-9fc124207f58",
   "metadata": {},
   "source": [
    "## Creating Our Own Tokenizer\n",
    "\n",
    "Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c581b33-c92e-4525-b744-a0bba43db8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration tglcourse--abc_tunes-5a89386c12e016f6\n",
      "Reusing dataset parquet (/root/.cache/huggingface/datasets/tglcourse___parquet/tglcourse--abc_tunes-5a89386c12e016f6/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Title': \"Pat Hogan's One\",\n",
       " 'Time Signature': '2/4',\n",
       " 'L': '1/8',\n",
       " 'Key': 'Edor',\n",
       " 'Tune': 'D>D FA|dc BA|BE EF|GA/G/ FE|D>D FA|dcBA|Be Bc|d2 d2:||:eB eB|eB B>c|dA dA|dA A2|eB eB|eB B>c|dB AF|E2 E2:|'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('tglcourse/abc_tunes', split='train').shuffle()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462647f-6300-4c80-8c82-2c0697ad8a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 100 # Explore different vocab sizes\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer =BpeTrainer(special_tokens=[\"[UNK]\", \"[PAD]\"],\n",
    "                    vocab_size=vocab_size) \n",
    "tokenizer.train_from_iterator(dataset['Tune'], trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd291f7-e810-4a5f-be37-20bef8ea30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer,\n",
    "                                    pad_token=\"[PAD]\",\n",
    "                                    unk_token=\"[UNK]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefab8a5-cc4f-4530-a0a7-71efd5a66625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOSee the docs for pre-tokenizer options: https://huggingface.co/docs/tokenizers/quicktour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71506c-a4c1-4fc5-9262-71cb47ec4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??tokenizer.train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04260a-56bf-4f17-b232-2ca00780d0cb",
   "metadata": {},
   "source": [
    "Printing out the decoded string (using '#' as a separator) we ca see how the tune has turned into discrete tokens, some of thich are individual notes but many of which are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682db0a7-bc07-49f8-b645-fe86e8cd3da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 34, 40, 4, 42, 37, 95, 71, 70, 4, 38, 37, 95, 38, 41, 4, 41, 42, 95, 43, 37, 19, 43, 19, 4, 42, 41, 95, 40, 34, 40, 4, 42, 37, 95, 71, 70, 38, 37, 95, 38, 72, 4, 38, 70, 95, 71, 22, 4, 71, 22, 30, 95, 95, 30, 72, 38, 4, 72, 38, 95, 72, 38, 4, 38, 34, 70, 95, 71, 37, 4, 71, 37, 95, 71, 37, 4, 37, 22, 95, 72, 38, 4, 72, 38, 95, 72, 38, 4, 38, 34, 70, 95, 71, 38, 4, 37, 42, 95, 41, 22, 4, 41, 22, 30, 95]\n",
      "D#>#D# #F#A#|#d#c# #B#A#|#B#E# #E#F#|#G#A#/#G#/# #F#E#|#D#>#D# #F#A#|#d#c#B#A#|#B#e# #B#c#|#d#2# #d#2#:#|#|#:#e#B# #e#B#|#e#B# #B#>#c#|#d#A# #d#A#|#d#A# #A#2#|#e#B# #e#B#|#e#B# #B#>#c#|#d#B# #A#F#|#E#2# #E#2#:#|\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(dataset[0]['Tune']) # .ids if using the Tokenizer version\n",
    "print(ids)\n",
    "decoded = '#'.join([tokenizer.decode([t]) for t in ids])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca74ec-9c92-41fd-839d-899a51e98e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': 84, '}': 96, 'í': 107, 'e': 72, '@': 36, 't': 87, 'ó': 109, 'U': 57, 'i': 76, '6': 26, '(': 12, 'b': 69, 'º': 101, '~': 97, 'f': 73, 'v': 89, '\\t': 3, 'Q': 53, 'S': 55, '0': 20, '#': 7, '4': 24, 'Z': 62, 'ä': 104, 'T': 56, 'D': 40, '\\x08': 2, '/': 19, '9': 29, 'G': 43, 'Y': 61, ')': 13, 'A': 37, '.': 18, 'I': 45, 'J': 46, 'á': 103, 'è': 105, 'V': 58, \"'\": 11, '^': 66, 'o': 82, '¬': 100, 'm': 80, '=': 33, 'p': 83, '!': 5, '[PAD]': 1, 'd': 71, 'z': 93, 'Ú': 102, '5': 25, ':': 30, '\"': 6, '+': 15, 'M': 49, '$': 8, '<': 32, '&': 10, 'H': 44, 'N': 50, 'h': 75, 'é': 106, 'ñ': 108, 'F': 42, '*': 14, '\\\\': 64, 'l': 79, '[UNK]': 0, '2': 22, 'L': 48, 'E': 41, 'K': 47, 'a': 68, '\\xa0': 98, 'R': 54, '7': 27, 'k': 78, '3': 23, ',': 16, '[': 63, '%': 9, 'ú': 110, 'n': 81, 'w': 90, 's': 86, 'c': 70, 'P': 52, '_': 67, 'y': 92, 'X': 60, ']': 65, 'r': 85, ';': 31, 'W': 59, '-': 17, 'u': 88, '8': 28, 'x': 91, 'g': 74, '{': 94, '|': 95, 'ª': 99, '>': 34, ' ': 4, '?': 35, '1': 21, 'B': 38, 'C': 39, 'O': 51, 'j': 77}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e8521-0df7-4f8c-a76d-b26c40982207",
   "metadata": {},
   "source": [
    "## An Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f667a-d852-4d6a-b863-594e61cc0ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(100, 32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 32\n",
    "emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca3e06-2111-43b7-b5e0-24340cccd365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer(torch.tensor(ids)).shape # Passing our tokens through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b432e-b24a-4514-acff-f1174ebf9e6a",
   "metadata": {},
   "source": [
    "## A simple MLP\n",
    "\n",
    "Similar to Karpathy's makemore demo (TODO link)\n",
    "\n",
    "How do we work with sequences of different lengths? Padding + truncation seem non-ideal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc6b27-714c-4602-a583-c6cb28b60791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "seq_len=64\n",
    "batch_ids = torch.randint(vocab_size, (batch_size,seq_len))\n",
    "batch_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8fe08-b14e-4a83-9ae0-d13931bce3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer(batch_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c4035-4233-400f-b93c-5100189b402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A minimal model (output sizes shown\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_size, emb_dim), # (batch_size, seq_length, emb_dim)\n",
    "    nn.Flatten(), # (batch_size, seq_length*emb_dim)\n",
    "    nn.Linear(emb_dim*seq_len, 64), # (batch_size, 64)\n",
    "    nn.ReLU(), # (batch_size, 64)\n",
    "    nn.Linear(64, 2), # (batch_size, 2)\n",
    "    \n",
    ")\n",
    "model(batch_ids).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00720574-aab9-404a-8538-5b282399b8bb",
   "metadata": {},
   "source": [
    "Q: What happens when word position changes?\n",
    "Q: Would this work on different length sequences?\n",
    "Q: think of more Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d3f2c-4773-4e25-b1db-12498b7cbc34",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks and LSTMs\n",
    "\n",
    "Explain the basic architecture\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "![an unrolled RNN](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
    "\n",
    "Maybe demo?\n",
    "\n",
    "Brief hand-wave explanation of LSTMs and link ULMFIT and co for the curious\n",
    "\n",
    "Great blog by colah https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "Karpathy on RNN effectiveness: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36c3b0-25de-499d-bf0b-06defc913e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 8, 20]), torch.Size([1, 8, 20]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the RNN\n",
    "input_size = 10 # Number of features in the input (embedding dim)\n",
    "hidden_size = 20 # Number of features in the hidden state h\n",
    "num_layers = 1 # Set to 2 for a 'stacked' RNN with 2 layers\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers) # The model\n",
    "\n",
    "# Run some dummy data through\n",
    "# Create the model with batch_first=True if you'd like the batch dimension to come first\n",
    "batch_size = 8\n",
    "input_length = 5\n",
    "x = torch.randn(5, batch_size, input_size)\n",
    "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "output, hn = rnn(x, h0)\n",
    "\n",
    "# Check the output shapes\n",
    "output.shape, hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf33b33-6c86-4384-a86f-81083c7ff7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size=10, hidden_size=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.emb_layer = nn.Embedding(vocab_size, input_size)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers)\n",
    "        self.mlp = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb_layer(x) # TO embeddings (batch_size, seq_len, input_size)\n",
    "        net_output, h = self.rnn(x) # Through RNN (batch_size, seq_len, hidden_size)\n",
    "        averaged_output = net_output.mean(dim=1) # Take the mean of the outputs ('mean pooling')\n",
    "        result = self.mlp(averaged_output) # THrough the linear layer or MLP to get 2 outputs (assuming binary classification)\n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c1f5e-5116-4793-a158-cb7bbc5a2472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MyRNNClassifier()\n",
    "net(batch_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f897aa-527f-4d9e-b9a9-5de126544f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2522"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99478a-433a-40ed-b7e1-5d7390f5b4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([100, 10]),\n",
       " torch.Size([20, 10]),\n",
       " torch.Size([20, 20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([20, 20]),\n",
       " torch.Size([20, 20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([20]),\n",
       " torch.Size([2, 20]),\n",
       " torch.Size([2])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d9c2f-83d8-45d3-9d43-0fe004ffe548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try on some data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073b4c1-67da-416e-a3f1-021b5ecad590",
   "metadata": {},
   "source": [
    "**LSTMs**\n",
    "\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "something something memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7affb6d-47c6-4b1a-9c38-29869e2a9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=10, hidden_size=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.emb_layer = nn.Embedding(vocab_size, input_size)\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers)\n",
    "        self.mlp = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb_layer(x) # TO embeddings (batch_size, seq_len, input_size)\n",
    "        net_output, h = self.rnn(x) # Through RNN (batch_size, seq_len, hidden_size)\n",
    "        averaged_output = net_output.mean(dim=1) # Take the mean of the outputs ('mean pooling')\n",
    "        result = self.mlp(averaged_output) # THrough the linear layer or MLP to get 2 outputs (assuming binary classification)\n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5042-f359-4a5d-96fe-9239d85cf2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MyLSTMClassifier()\n",
    "net(batch_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502b18d-7027-4d74-b8d0-f363794a6705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6962"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6643e-7962-4706-bd65-a80f6fb6d1e3",
   "metadata": {},
   "source": [
    "## Using Learned Representations\n",
    "\n",
    "Do review classification or something using a learned embedding combined with an RNN? Or model tunes and then classify into type/key/mode?\n",
    "\n",
    "Yeah tunes will be good. LM objective first, then re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf98bfb-057c-46c6-ae8d-6aac885888ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self, input_size=32, hidden_size=128, num_layers=2, vocab_size=200):\n",
    "        super().__init__()\n",
    "        self.emb_layer = nn.Embedding(vocab_size, input_size)\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers)\n",
    "        self.mlp = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb_layer(x) # TO embeddings (batch_size, seq_len, input_size)\n",
    "        rnn_output, h = self.rnn(x) # Through RNN (batch_size, seq_len, hidden_size)\n",
    "        return self.mlp(rnn_output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5ebe9-cf90-4243-b9a4-2dda41ba242a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 105]), torch.Size([1, 105, 200]), torch.Size([1, 105]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LM()\n",
    "tokeized_tune = torch.tensor([tokenizer.encode(dataset[0]['Tune'])])\n",
    "x = tokeized_tune[:,:-1] # All but the last token\n",
    "y = tokeized_tune[:,1:] # All but the first token (x shifted by 1)\n",
    "x.shape, lm(x).shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422fd4ad-bd76-4bd0-b2d2-6031326fea41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 339])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(tokenizer(dataset['Tune'][:10], padding=True)['input_ids']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a5093-100e-499c-b8c7-9cafadae73a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2998, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lm_loss_function(model_pred, y):\n",
    "    b, n, vc = model_pred.shape\n",
    "    pred = model_pred.reshape(b*n, vc)\n",
    "    target = y.flatten()\n",
    "    return nn.functional.cross_entropy(pred, target)\n",
    "\n",
    "lm_loss_function(lm(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c60405-c6e8-42be-bfca-3dafc023bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e6561-a246-45f7-8bab-23f54e82d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration tglcourse--abc_tunes-5a89386c12e016f6\n",
      "Reusing dataset parquet (/root/.cache/huggingface/datasets/tglcourse___parquet/tglcourse--abc_tunes-5a89386c12e016f6/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('tglcourse/abc_tunes', split='train').shuffle()\n",
    "max_length = 201\n",
    "tokenized_tunes = tokenizer(dataset['Tune'], padding=True, truncation=True, max_length=max_length)['input_ids']\n",
    "lm_dataset = Dataset.from_dict({\n",
    "    'x':torch.tensor([t[:-1] for t in tokenized_tunes]),\n",
    "    'y':torch.tensor([t[1:] for t in tokenized_tunes]),\n",
    "})\n",
    "lm_dataloader = torch.utils.data.DataLoader(lm_dataset.with_format(\"torch\"), batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1363766-b32e-4108-97a1-d9df1b7e99e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 200]), torch.Size([256, 200]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(lm_dataloader))\n",
    "batch['x'].shape, batch['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd556f5a-8038-49e2-a486-e85e439f87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84730d-41d7-4485-91e2-1b74b59855c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2302859e510249b193f8ad0effce73f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fe1c6556e648d58841c1ca2bc3df8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728efc0441bf4fceb65efd7fc82c39c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a190fcb2487a4093bdbfcf354e9e9d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c9f38e211b46d6bc3aec4d8a1b25ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e378979074449298bfd83d16040fc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916a6a4951f04e87a2f91b21ba5b5715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de21cefc8bf04504aa33fe0baf5fa8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bbc4f400b8415fac2e889ce8bcbed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce6c3df4f124c7cad2de84012cd6b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = LM().cuda()\n",
    "optimizer = torch.optim.Adam(lm.parameters(), lr=1e-4)\n",
    "losses = []\n",
    "for epoch in range(10):\n",
    "    for batch in tqdm(lm_dataloader):\n",
    "        x = batch['x'].cuda()\n",
    "        y = batch['y'].cuda()\n",
    "        model_preds = lm(x)\n",
    "        loss = lm_loss_function(lm(x), y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaeaeb-3266-4b47-bb6d-2141deb99f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b1289-0ca8-470a-a2d6-0d59f54bdaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B | F b Z X, c : Y º B l [ B'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def generate(model, start_text, n, max_length=200, top_k=None):\n",
    "    model.eval()\n",
    "    tokenized_start = torch.tensor([tokenizer(start_text)['input_ids']]).cuda()\n",
    "    x = tokenized_start\n",
    "    for i in range(n):\n",
    "        model_pred = model(x)\n",
    "        last_word_logits = model_pred[0][0]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).data\n",
    "        \n",
    "        # Set p to zero for special tokens we don't want\n",
    "        p[:4] = 0\n",
    "        \n",
    "        # Sample\n",
    "        if top_k is None:\n",
    "            candidate_tokens = np.arange(len(last_word_logits))\n",
    "        else:\n",
    "            p, candidate_tokens = p.topk(top_k)\n",
    "            candidate_tokens = candidate_tokens.detach().cpu().numpy().squeeze()\n",
    "        p = p.detach().cpu().numpy().squeeze()\n",
    "        word_index = np.random.choice(candidate_tokens, p=p/p.sum())\n",
    "        x = torch.cat([x, torch.tensor([[word_index]]).cuda()], dim=-1)\n",
    "        \n",
    "    return tokenizer.decode(x.flatten())\n",
    "generate(lm, 'B|F', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a4785-25d5-4348-8b43-f38629e53321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B | F 2 e F 3 ( ( a / A c E A E \" \" a d a g c E D :   A c   B F   f G : / d   a c A : f D E ( a \" e 2 D 2 F 2 3 E \" c a f 2 2 A G \" d E / E G c 2 / D a | 2 B D f B B   g e c e d B e g   ( f ( D g 3 G e : c g g g ( : | 2 2 / : a \" F G c 3 f \" F / | f \" c E 3 F a g F | f e G 2 D f E d E f a g G ( 3 c g ( G / E F 3 : ( \" 2 3 2 ( e G G E c / A g : / B e a / /   d : A f c / : E 2 \" f : 3 G | / | d | / F \" F'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(lm, 'B|F', 200,top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa46c78-75f4-439f-9314-bdb45d1d3339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247240"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in lm.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948ef50-3e0e-4bb1-999c-65652ef91d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try on some data (LM first then new classification head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3d757-227e-47d0-8158-4d1dc5c318cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO talk about efficiency of training vs sampling\n",
    "# TODO demo different sampling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbaa58-e6d4-4ea2-9d37-d9df4143542f",
   "metadata": {},
   "source": [
    "Page stats: Total Hits: [![HitCount](https://hits.dwyl.com/johnowhitaker/tglcourse.svg?style=flat-square&show=unique)](http://hits.dwyl.com/johnowhitaker/tglcourse)\n",
    "Page visitors:\n",
    "![visitor badge](https://page-views.glitch.me/badge?page_id=tglcourse.l09)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
